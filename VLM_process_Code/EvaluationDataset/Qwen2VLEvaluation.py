import json
import torch
from transformers import Qwen2VLForConditionalGeneration, AutoProcessor
from qwen_vl_utils import process_vision_info
import os

# Parameter settings
dataset_path = "/home/ubuntu/Desktop/dataset/droidJsonDatset/qwenvl_2b_qwenvl_2b_updated_dataset.json"  # Dataset file path
save_path = "/home/ubuntu/Desktop/dataset/droidJsonDatset/qwenvl_2b_qwenvl_2b_updated_dataset_EvaluationResult.json"  # Path to save results
model_path = "/home/ubuntu/Desktop/Qwen2-VL-2B-Instruct"

# Device setup
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Load model
model = Qwen2VLForConditionalGeneration.from_pretrained(model_path, ignore_mismatched_sizes=True).to(device)
processor = AutoProcessor.from_pretrained(model_path)

# Scoring weights
alpha, beta, gamma = 0.4, 0.3, 0.3  # Weights for visual, temporal, and physical aspects

def evaluate_with_model(video_path, gpt_value, eval_type):
    """Evaluate the video and the GPT-generated task plan using Qwen2-VL."""
    messages = [
        {
            "role": "user",
            "content": [
                {"type": "text", "text": f"Please evaluate if the following task description meets the {eval_type} requirement and provide a score from 0 to 1: " + gpt_value},
                {"type": "video", "video": video_path},
            ],
        }
    ]

    # Process inputs
    text = processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)
    _, video_inputs = process_vision_info(messages)
    inputs = processor(text=[text], videos=video_inputs, padding=True, return_tensors="pt").to(device)

    # Inference
    with torch.no_grad():
        generated_ids = model.generate(**inputs, max_new_tokens=32)
    output_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]

    # Extract the score (assuming the model returns a value between 0 and 1)
    try:
        score = float(output_text.strip())
        score = max(0.0, min(1.0, score))  # Clamp the value between 0 and 1
    except (ValueError, TypeError):
        score = 0.5  # Assign a default value if parsing fails

    return score


# Load the dataset
with open(dataset_path, "r", encoding="utf-8") as f:
    dataset = json.load(f)

results = []
for sample in dataset:
    video_path = sample["videos"][0]
    gpt_value = sample["conversations"][-1]["value"]  # Task plan generated by GPT

    s_vision = evaluate_with_model(video_path, gpt_value, "visual consistency")
    s_temporal = evaluate_with_model(video_path, gpt_value, "temporal consistency")
    s_physical = evaluate_with_model(video_path, gpt_value, "physical feasibility")

    # Calculate the final score
    final_score = alpha * s_vision + beta * s_temporal + gamma * s_physical

    results.append({
        "video": video_path,
        "gpt_value": gpt_value,
        "S_vision": s_vision,
        "S_temporal": s_temporal,
        "S_physical": s_physical,
        "final_score": final_score
    })

# Save the evaluation results
with open(save_path, "w", encoding="utf-8") as f:
    json.dump(results, f, indent=4, ensure_ascii=False)

print(f"Evaluation complete. Results have been saved to {save_path}")